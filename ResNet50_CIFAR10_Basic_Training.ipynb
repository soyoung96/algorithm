{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50 CIFAR10 Basic Training",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyoung96/algorithm/blob/master/ResNet50_CIFAR10_Basic_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2SSsQMSknm2"
      },
      "source": [
        "#### <b>ResNet50 모델 아키텍처 정의</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpUcgk5xkgGZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "\n",
        "# ResNet50을 위해 최대한 간단히 수정한 BasicBlock 클래스\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # 1x1 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
        "\n",
        "        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
        "\n",
        "        # 1x1 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
        "        self.conv3 = nn.Conv2d(planes, planes*4, kernel_size=1,  bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes*4) # 배치 정규화(batch normalization)\n",
        "\n",
        "        self.shortcut = nn.Sequential() # identity인 경우\n",
        "        if stride != 1 or in_planes != 4*planes: # stride가 1이 아니라면, identity mapping이 아닌 경우\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, 4 * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(4*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x) # (핵심) skip connection\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ResNet 클래스 정의\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        # 64개의 3x3 필터(filter)를 사용\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Conv2d(4*512, num_classes,kernel_size=1) #바꿈\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes*4 # 다음 레이어를 위해 채널 수 변경\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out) # 출력: [batch_size, 512, 4, 4]\n",
        "        out = F.avg_pool2d(out, 4) # 출력: [batch_size, 512, 1, 1]\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ResNet18 함수 정의\n",
        "def ResNet50():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCNacrgtktlr"
      },
      "source": [
        "#### <b>데이터셋(Dataset) 다운로드 및 불러오기</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmmQZ8p5kq_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c9ac3c-36c4-498e-a3a4-cff4d2497373"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F \n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.pylab as plt2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "#Check GPU, connect to it if it is available \n",
        "device = ''\n",
        "if torch.cuda.is_available():\n",
        "\tdevice = 'cuda'\n",
        "\tprint(\"CUDA is available. GPU will be used for training.\")\n",
        "else:\n",
        "\tdevice = 'cpu'\n",
        "\n",
        "\n",
        "BEST_ACCURACY = 0\n",
        "\n",
        "# Preparing Data\n",
        "print(\"==> Prepairing data ...\")\n",
        "#Transformation on train data\n",
        "transform_train = transforms.Compose([\n",
        "\ttransforms.RandomCrop(32, padding=4),\n",
        "\ttransforms.RandomHorizontalFlip(),\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010)),\n",
        "\t])\n",
        "\n",
        "#transformation on validation data\n",
        "transform_validation = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "\t])\n",
        "\n",
        "#Download Train and Validation data and apply transformation\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "validation_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_validation)\n",
        "\n",
        "#Put data into trainloader, specify batch_size\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=100, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#Function to show CIFAR images\n",
        "def show_data(image):\n",
        "\tplt.imshow(np.transpose(image[0], (1, 2, 0)), interpolation='bicubic')\n",
        "\tplt.show()\n",
        "\n",
        "#show_data(train_data[0])\n",
        "\n",
        "\n",
        "#Need to import model a model\n",
        "model = ResNet50()\n",
        "#model = ResNet34()\n",
        "#model = CNN_batch()\n",
        "#Pass model to GPU\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "length_train = len(train_data)\n",
        "length_validation = len(validation_data)\n",
        "#print(length_train)\n",
        "#print(len(train_loader))\n",
        "num_classes = 10\n",
        "\n",
        "#Training\n",
        "def train(epochs):\n",
        "\tglobal BEST_ACCURACY\n",
        "\tdict = {'Train Loss':[], 'Train Acc':[], 'Validation Loss':[], 'Validation Acc':[]}\n",
        "\tfor epoch in range(epochs):\n",
        "\t\tprint(\"\\nEpoch:\", epoch+1, \"/\", epochs)\n",
        "\t\tcost = 0\n",
        "\t\tcorrect = 0\n",
        "\t\ttotal = 0\n",
        "\t\twoha = 0\n",
        "\n",
        "\t\tfor i, (x,y) in enumerate(train_loader):\n",
        "\t\t\twoha += 1\n",
        "\t\t\tmodel.train()\n",
        "\t\t\tx, y = x.to(device), y.to(device)\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tyhat = model(x)\n",
        "\t\t\tyhat = yhat.reshape(-1, 10)\n",
        "\t\t\tloss = criterion(yhat, y)\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\tcost += loss.item()\n",
        "\n",
        "\t\t\t_, yhat2 = torch.max(yhat.data, 1)\n",
        "\t\t\tcorrect += (yhat2 == y).sum().item()\n",
        "\t\t\ttotal += y.size(0)\n",
        "\n",
        "\t\tmy_loss = cost/len(train_loader)\n",
        "\t\tmy_accuracy = 100*correct/length_train\n",
        "\n",
        "\t\tdict['Train Loss'].append(my_loss)\n",
        "\t\tdict['Train Acc'].append(my_accuracy)\n",
        "\n",
        "\t\tprint('Tain Loss:', my_loss)\n",
        "\t\tprint('Train Accuracy:', my_accuracy,'%')\n",
        "\n",
        "\n",
        "\t\tcost = 0\n",
        "\t\tcorrect = 0\n",
        "\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tfor x, y in validation_loader:\n",
        "\t\t\t\tx, y = x.to(device), y.to(device)\n",
        "\t\t\t\tmodel.eval()\n",
        "\t\t\t\tyhat = model(x)\n",
        "\t\t\t\tyhat = yhat.reshape(-1, 10)\n",
        "\t\t\t\tloss = criterion(yhat, y)\n",
        "\t\t\t\tcost += loss.item()\n",
        "\t\t\t\t\n",
        "\t\t\t\t_, yhat2 = torch.max(yhat.data, 1)\n",
        "\t\t\t\tcorrect += (yhat2 == y).sum().item()\n",
        "\n",
        "\t\tmy_loss = cost/len(validation_loader)\n",
        "\t\tmy_accuracy = 100*correct/length_validation\n",
        "\n",
        "\t\tdict['Validation Loss'].append(my_loss)\n",
        "\t\tdict['Validation Acc'].append(my_accuracy)\n",
        "\n",
        "\t\tprint('Validation Loss:', my_loss)\n",
        "\t\tprint('Validation Accuracy:', my_accuracy,'%')\n",
        "\n",
        "\t\t#Save the model if you get best accuracy on validation data\n",
        "\t\tif my_accuracy > BEST_ACCURACY:\n",
        "\t\t\tBEST_ACCURACY = my_accuracy\n",
        "\t\t\tprint('Saving the model ...')\n",
        "\t\t\tmodel.eval()\n",
        "\t\t\tif not os.path.isdir('checkpoint'):\n",
        "\t\t\t    os.mkdir('checkpoint')\n",
        "\t\t\ttorch.save(model.state_dict(), './checkpoint/resnet50.pth')\n",
        "\n",
        "\tprint(\"TRAINING IS FINISHED !!!\")\n",
        "\treturn dict\n",
        "\n",
        "#Start training\n",
        "results = train(40)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available. GPU will be used for training.\n",
            "==> Prepairing data ...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 1 / 40\n",
            "Tain Loss: 1.811822697329704\n",
            "Train Accuracy: 34.978 %\n",
            "Validation Loss: 1.3918440628051758\n",
            "Validation Accuracy: 50.17 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 2 / 40\n",
            "Tain Loss: 1.2346497118625495\n",
            "Train Accuracy: 55.392 %\n",
            "Validation Loss: 1.0545808124542235\n",
            "Validation Accuracy: 62.5 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 3 / 40\n",
            "Tain Loss: 0.9595536114004872\n",
            "Train Accuracy: 66.112 %\n",
            "Validation Loss: 1.0120917254686355\n",
            "Validation Accuracy: 66.87 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 4 / 40\n",
            "Tain Loss: 0.7841031276966299\n",
            "Train Accuracy: 72.566 %\n",
            "Validation Loss: 0.7687614697217942\n",
            "Validation Accuracy: 73.18 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 5 / 40\n",
            "Tain Loss: 0.6524009110830019\n",
            "Train Accuracy: 77.314 %\n",
            "Validation Loss: 0.8402917361259461\n",
            "Validation Accuracy: 73.25 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 6 / 40\n",
            "Tain Loss: 0.5565776464426914\n",
            "Train Accuracy: 80.698 %\n",
            "Validation Loss: 0.5794846546649933\n",
            "Validation Accuracy: 80.72 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 7 / 40\n",
            "Tain Loss: 0.49103846017966796\n",
            "Train Accuracy: 83.078 %\n",
            "Validation Loss: 0.4886571338772774\n",
            "Validation Accuracy: 83.35 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 8 / 40\n",
            "Tain Loss: 0.4453966064221414\n",
            "Train Accuracy: 84.55 %\n",
            "Validation Loss: 0.5625957131385804\n",
            "Validation Accuracy: 81.45 %\n",
            "\n",
            "Epoch: 9 / 40\n",
            "Tain Loss: 0.40342641692332293\n",
            "Train Accuracy: 85.906 %\n",
            "Validation Loss: 0.4849344611167908\n",
            "Validation Accuracy: 83.78 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 10 / 40\n",
            "Tain Loss: 0.37317068367967826\n",
            "Train Accuracy: 87.094 %\n",
            "Validation Loss: 0.5140870852768421\n",
            "Validation Accuracy: 82.89 %\n",
            "\n",
            "Epoch: 11 / 40\n",
            "Tain Loss: 0.34322206916101755\n",
            "Train Accuracy: 88.082 %\n",
            "Validation Loss: 0.509120147228241\n",
            "Validation Accuracy: 83.79 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 12 / 40\n",
            "Tain Loss: 0.32149062387626187\n",
            "Train Accuracy: 88.884 %\n",
            "Validation Loss: 0.44367033466696737\n",
            "Validation Accuracy: 85.31 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 13 / 40\n",
            "Tain Loss: 0.29929561882525146\n",
            "Train Accuracy: 89.678 %\n",
            "Validation Loss: 0.5105280864238739\n",
            "Validation Accuracy: 83.34 %\n",
            "\n",
            "Epoch: 14 / 40\n",
            "Tain Loss: 0.2775741258964819\n",
            "Train Accuracy: 90.524 %\n",
            "Validation Loss: 0.36601628109812734\n",
            "Validation Accuracy: 87.64 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 15 / 40\n",
            "Tain Loss: 0.25915526276659173\n",
            "Train Accuracy: 90.96 %\n",
            "Validation Loss: 0.43223158568143843\n",
            "Validation Accuracy: 86.41 %\n",
            "\n",
            "Epoch: 16 / 40\n",
            "Tain Loss: 0.24481363729823885\n",
            "Train Accuracy: 91.428 %\n",
            "Validation Loss: 0.37193405866622925\n",
            "Validation Accuracy: 87.47 %\n",
            "\n",
            "Epoch: 17 / 40\n",
            "Tain Loss: 0.22929783645645738\n",
            "Train Accuracy: 91.862 %\n",
            "Validation Loss: 0.4429100681096315\n",
            "Validation Accuracy: 86.8 %\n",
            "\n",
            "Epoch: 18 / 40\n",
            "Tain Loss: 0.22412754025529413\n",
            "Train Accuracy: 92.114 %\n",
            "Validation Loss: 0.39558134086430075\n",
            "Validation Accuracy: 87.78 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 19 / 40\n",
            "Tain Loss: 0.2082608915350931\n",
            "Train Accuracy: 92.694 %\n",
            "Validation Loss: 0.3821351885795593\n",
            "Validation Accuracy: 88.21 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 20 / 40\n",
            "Tain Loss: 0.1997434398745332\n",
            "Train Accuracy: 92.966 %\n",
            "Validation Loss: 0.4668240198493004\n",
            "Validation Accuracy: 85.91 %\n",
            "\n",
            "Epoch: 21 / 40\n",
            "Tain Loss: 0.19220701157284514\n",
            "Train Accuracy: 93.342 %\n",
            "Validation Loss: 0.3463113260269165\n",
            "Validation Accuracy: 88.91 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 22 / 40\n",
            "Tain Loss: 0.18431937044767469\n",
            "Train Accuracy: 93.648 %\n",
            "Validation Loss: 0.40847432270646095\n",
            "Validation Accuracy: 88.02 %\n",
            "\n",
            "Epoch: 23 / 40\n",
            "Tain Loss: 0.17646426174913526\n",
            "Train Accuracy: 93.818 %\n",
            "Validation Loss: 0.32472516104578975\n",
            "Validation Accuracy: 89.67 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 24 / 40\n",
            "Tain Loss: 0.16685625238110646\n",
            "Train Accuracy: 94.146 %\n",
            "Validation Loss: 0.38296504646539686\n",
            "Validation Accuracy: 88.31 %\n",
            "\n",
            "Epoch: 25 / 40\n",
            "Tain Loss: 0.15865272769461508\n",
            "Train Accuracy: 94.47 %\n",
            "Validation Loss: 0.340692410543561\n",
            "Validation Accuracy: 89.84 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 26 / 40\n",
            "Tain Loss: 0.1551327040357053\n",
            "Train Accuracy: 94.524 %\n",
            "Validation Loss: 0.37333189085125923\n",
            "Validation Accuracy: 89.06 %\n",
            "\n",
            "Epoch: 27 / 40\n",
            "Tain Loss: 0.14791596416012406\n",
            "Train Accuracy: 94.908 %\n",
            "Validation Loss: 0.32750540643930437\n",
            "Validation Accuracy: 90.12 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 28 / 40\n",
            "Tain Loss: 0.13987061840570186\n",
            "Train Accuracy: 95.116 %\n",
            "Validation Loss: 0.3641805330663919\n",
            "Validation Accuracy: 89.3 %\n",
            "\n",
            "Epoch: 29 / 40\n",
            "Tain Loss: 0.13440559972125246\n",
            "Train Accuracy: 95.266 %\n",
            "Validation Loss: 0.4304498097300529\n",
            "Validation Accuracy: 87.89 %\n",
            "\n",
            "Epoch: 30 / 40\n",
            "Tain Loss: 0.13606412115190036\n",
            "Train Accuracy: 95.292 %\n",
            "Validation Loss: 0.3419484271109104\n",
            "Validation Accuracy: 90.02 %\n",
            "\n",
            "Epoch: 31 / 40\n",
            "Tain Loss: 0.13052011657591975\n",
            "Train Accuracy: 95.488 %\n",
            "Validation Loss: 0.357704346999526\n",
            "Validation Accuracy: 89.63 %\n",
            "\n",
            "Epoch: 32 / 40\n",
            "Tain Loss: 0.1217511175557628\n",
            "Train Accuracy: 95.642 %\n",
            "Validation Loss: 0.44658596500754355\n",
            "Validation Accuracy: 87.21 %\n",
            "\n",
            "Epoch: 33 / 40\n",
            "Tain Loss: 0.12796712616253691\n",
            "Train Accuracy: 95.418 %\n",
            "Validation Loss: 0.3457485681772232\n",
            "Validation Accuracy: 90.1 %\n",
            "\n",
            "Epoch: 34 / 40\n",
            "Tain Loss: 0.11680597999630987\n",
            "Train Accuracy: 95.864 %\n",
            "Validation Loss: 0.3633509096503258\n",
            "Validation Accuracy: 89.89 %\n",
            "\n",
            "Epoch: 35 / 40\n",
            "Tain Loss: 0.1199363518001326\n",
            "Train Accuracy: 95.716 %\n",
            "Validation Loss: 0.318871958553791\n",
            "Validation Accuracy: 90.69 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 36 / 40\n",
            "Tain Loss: 0.11422884648146532\n",
            "Train Accuracy: 96.032 %\n",
            "Validation Loss: 0.36749307334423065\n",
            "Validation Accuracy: 89.43 %\n",
            "\n",
            "Epoch: 37 / 40\n",
            "Tain Loss: 0.11047000042579667\n",
            "Train Accuracy: 96.082 %\n",
            "Validation Loss: 0.37185283429920674\n",
            "Validation Accuracy: 90.12 %\n",
            "\n",
            "Epoch: 38 / 40\n",
            "Tain Loss: 0.1088250047048492\n",
            "Train Accuracy: 96.184 %\n",
            "Validation Loss: 0.32346342839300635\n",
            "Validation Accuracy: 90.91 %\n",
            "Saving the model ...\n",
            "\n",
            "Epoch: 39 / 40\n",
            "Tain Loss: 0.1068532136757203\n",
            "Train Accuracy: 96.268 %\n",
            "Validation Loss: 0.34629789762198926\n",
            "Validation Accuracy: 90.13 %\n",
            "\n",
            "Epoch: 40 / 40\n",
            "Tain Loss: 0.1057588547430075\n",
            "Train Accuracy: 96.206 %\n",
            "Validation Loss: 0.3405139249563217\n",
            "Validation Accuracy: 90.51 %\n",
            "TRAINING IS FINISHED !!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl1-47E7pHD_"
      },
      "source": [
        "#### <b>환경 설정 및 학습(Training) 함수 정의</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhm_eVykk-Z8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "c6f2b8f0-73d2-48a0-a0a4-78b45f9249d1"
      },
      "source": [
        "plt.figure(1)\n",
        "plt.plot(results['Train Loss'], 'b', label = 'training loss')\n",
        "plt.plot(results['Validation Loss'], 'r', label = 'validation loss')\n",
        "plt.title(\"LOSS\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['training set', 'validation set'], loc='center right')\n",
        "plt.savefig('Loss_ResNet50.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(results['Train Acc'], 'b', label = 'training accuracy')\n",
        "plt.plot(results['Validation Acc'], 'r', label = 'validation accuracy')\n",
        "plt.title(\"ACCURACY\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['training set', 'validation set'], loc='center right')\n",
        "plt.savefig('Accuracy_ResNet50.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6bdf896a2c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LOSS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mv5z7CEMRrn"
      },
      "source": [
        "#### <b>학습(Training) 진행</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4voLj7TKlaB1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "f656260f-268e-494e-b80f-b8df6809fd86"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F \n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.pylab as plt2\n",
        "import os\n",
        "\n",
        "#Check GPU, connect to it if it is available \n",
        "device = ''\n",
        "if torch.cuda.is_available():\n",
        "\tdevice = 'cuda'\n",
        "\tprint(\"CUDA is available. GPU will be used for testing.\")\n",
        "else:\n",
        "\tdevice = 'cpu'\n",
        "\n",
        "\n",
        "BEST_ACCURACY = 0\n",
        "\n",
        "# Preparing Data\n",
        "print(\"==> Prepairing data ...\")\n",
        "#transformation on validation data\n",
        "transform_validation = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "\t])\n",
        "\n",
        "#Download Validation data and apply transformation\n",
        "validation_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_validation)\n",
        "\n",
        "#Put data into loader, specify batch_size\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#Function to show CIFAR images\n",
        "def show_data(image):\n",
        "\tplt.imshow(np.transpose(image[0], (1, 2, 0)), interpolation='bicubic')\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "model = ResNet50()\n",
        "#model = ResNet34()\n",
        "model = model.to(device)\n",
        "print(\"Upload the model ...\")\n",
        "assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "model.load_state_dict(torch.load('./checkpoint/resnet50.pth'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "\t\"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "\tmaxk = max(topk)\n",
        "\t\n",
        "\t_, pred = output.topk(maxk, 1, True, True)\n",
        "\tpred = pred.t()\n",
        "\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\t\n",
        "\tres = []\n",
        "\tfor k in topk:\n",
        "\t    correct_k = correct[:k].view(-1).float().sum(0)\n",
        "\t    res.append(correct_k)\n",
        "\treturn res\n",
        "\n",
        "def test():\n",
        "\tmodel.eval()\n",
        "\twith torch.no_grad():\n",
        "\t\taccuracy1 = 0\n",
        "\t\taccuracy5 = 0\n",
        "\t\tfor x,y in validation_loader:\n",
        "\t\t\tx, y = x.to(device), y.to(device)\n",
        "\t\t\tmodel.eval()\n",
        "\t\t\tyhat = model(x)\n",
        "\t\t\tyhat = yhat.reshape(-1, 10)\n",
        "\t\t\ta1, a5 = accuracy(yhat, y, topk=(1,5))\n",
        "\t\t\taccuracy1 += a1 \n",
        "\t\t\taccuracy5 += a5\n",
        "\n",
        "\t\treturn (accuracy1/len(validation_data)).item(), (accuracy5/(len(validation_data))).item()\n",
        "\n",
        "\n",
        "acc1, acc5 = test()\n",
        "\n",
        "print(\"--------------------------\")\n",
        "print(\"|       ResNet50         |\")\n",
        "print(\"--------------------------\")\n",
        "print(\"| TOP1 Accuracy:\", format(100*acc1, '.4f'), \"|\")\n",
        "print(\"| TOP5 Accuracy:\", format(100*acc5, '.4f'), \"|\")\n",
        "print(\"--------------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[ Train epoch: 0 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-95e1a6a74d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTime elapsed:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-4cbed39c2005>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2385\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2387\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2388\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2389\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 1only batches of spatial targets supported (3D tensors) but got targets of size: : [128]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNXei2S_sA-S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}